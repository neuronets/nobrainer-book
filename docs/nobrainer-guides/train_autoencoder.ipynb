{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyFaW25Z-yjS"
      },
      "source": [
        "# Train a neural network for MRI representation learning using progressive auto-encoder\n",
        "\n",
        "In this notebook, we will use Nobrainer to train a model for brain MRI representation learning. Brain MRI representation learning using autoencoder structures is a useful unsupervised task for medical data compression or downstream supervised tasks. In particular, Nobrainer allows the training of an encoder network on its own to allow a projection of data into a predefined manifold. This can be used in the evaluation of performances of GAN models. \n",
        "\n",
        "In the following cells we will:\n",
        "1. Get sample T1-weighted MR scans as features\n",
        "2. Convert the data to TFRecords format\n",
        "3. Instantiate a progressive convolutional neural network for encoder and decoder\n",
        "4. Create a Dataset of the features\n",
        "5. Instantiate a trainer and choose a loss function to use\n",
        "6. Define whether the decoder network is fixed\n",
        "7. When working with a fixed decoder, download pre-trained decoders\n",
        "8. Train on part of the data in two phases (transition and resolution)\n",
        "9. Repeat steps 4-8 for each growing resolution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDjr4hyi-yjW"
      },
      "source": [
        "# Google Colaboratory\n",
        "\n",
        "If you are using Colab, please switch your runtime to GPU. To do this, select `Runtime > Change runtime type` in the top menu. Then select GPU under `Hardware accelerator`. A GPU greatly speeds up training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEsvkctQ-yjX"
      },
      "outputs": [],
      "source": [
        "!pip install --no-cache-dir nilearn nobrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYjuq3va-yjY"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o6h_1jC-yjY"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import nobrainer\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufeHFQ7j-yjZ"
      },
      "source": [
        "# Get sample features and labels\n",
        "\n",
        "We use 9 pairs of volumes for training and 1 pair of volunes for evaluation. Many more volumes would be required to train a model for any useful purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP6Llj_G-yjZ"
      },
      "outputs": [],
      "source": [
        "csv_of_filepaths = nobrainer.utils.get_data()\n",
        "filepaths = nobrainer.io.read_csv(csv_of_filepaths)\n",
        "\n",
        "train_paths = filepaths[:9]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQOwpUVr-yja"
      },
      "source": [
        "# Convert medical images to TFRecords\n",
        "\n",
        "Remember how many full volumes are in the TFRecords files. This will be necessary to know how many steps are in on training epoch. The default training method needs to know this number, because Datasets don't always know how many items they contain.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzD0gYDr-yja"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wyylb7tx-yjb"
      },
      "outputs": [],
      "source": [
        "resolution_batch_size_map = {8: 1, 16: 1, 32: 1, 64: 1, 128: 1, 256: 1} \n",
        "resolutions = sorted(list(resolution_batch_size_map.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhl8pDol-yjc"
      },
      "outputs": [],
      "source": [
        "nobrainer.tfrecord.write(\n",
        "    features_labels=train_paths,\n",
        "    filename_template='data/data-train_shard-{shard:03d}.tfrec',\n",
        "    examples_per_shard=3, # change for larger dataset\n",
        "    multi_resolution=True,\n",
        "    resolutions=resolutions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzPVr_A7-yjc"
      },
      "source": [
        "# Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgPsTJJT-yjc"
      },
      "outputs": [],
      "source": [
        "latent_size = 1024\n",
        "e_fmap_base = 2048\n",
        "d_fmap_base = 2048\n",
        "# latent_size = 1024 uncomment when sufficient compute is available\n",
        "# g_fmap_base = 4096 uncomment when sufficient compute is available\n",
        "# d_fmap_base = 4096 uncomment when sufficient compute is available\n",
        "num_parallel_calls = 4\n",
        "iterations = int(10)\n",
        "# iterations = int(300e3) uncomment when sufficient compute is available\n",
        "lr = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWkGTCJH-yjd"
      },
      "source": [
        "# Creating Logging Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB9e9iui-yjd"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "save_dir = 'pae'\n",
        "\n",
        "save_dir = Path(save_dir)\n",
        "generated_dir = save_dir.joinpath('generated')\n",
        "model_dir = save_dir.joinpath('saved_models')\n",
        "log_dir = save_dir.joinpath('logs')\n",
        "\n",
        "save_dir.mkdir(exist_ok=True)\n",
        "generated_dir.mkdir(exist_ok=True)\n",
        "model_dir.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmEiv-wy-yjd"
      },
      "source": [
        "# Instantiate a neural network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKOW6Z_I-yje"
      },
      "outputs": [],
      "source": [
        "encoder, decoder = nobrainer.models.progressiveae(latent_size, e_fmap_base=e_fmap_base, d_fmap_base=d_fmap_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44n3gS0G-yje"
      },
      "source": [
        "# Set pretrained decoder neural network paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1v-yXY5-yje"
      },
      "outputs": [],
      "source": [
        "fixed = False\n",
        "\n",
        "if fixed:\n",
        "    path = './mypaths/saved_models/'                     # if fixed=True, specify the folder in which *.h5 files are stored\n",
        "    model_paths = iter(sorted(glob.glob(path+'/*.h5')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0n_Qx1s-yje"
      },
      "source": [
        "# Training an autoencoder progressively for each resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "VxEg5480-yjf"
      },
      "outputs": [],
      "source": [
        "from nobrainer import training\n",
        "for resolution in resolutions:\n",
        "\n",
        "    # create a train dataset with features for resolution\n",
        "    dataset_train = nobrainer.dataset.get_dataset(\n",
        "        file_pattern=\"data/*res-%03d*.tfrec\"%(resolution),\n",
        "        batch_size=resolution_batch_size_map[resolution],\n",
        "        num_parallel_calls=num_parallel_calls,\n",
        "        volume_shape=(resolution, resolution, resolution),\n",
        "        n_classes=1, # dummy labels as this is unsupervised training\n",
        "        scalar_label=True,\n",
        "        normalizer=None\n",
        "    )\n",
        "\n",
        "\n",
        "    # grow the networks by one (2^x) resolution\n",
        "    encoder.add_resolution()\n",
        "\n",
        "    if fixed:\n",
        "        decoder = tf.keras.models.load_model(next(model_paths))\n",
        "    else:\n",
        "        decoder.add_resolution()\n",
        "\n",
        "    # instantiate a progressive training helper\n",
        "    progressive_ae_trainer = training.ProgressiveAETrainer(\n",
        "        encoder=encoder,\n",
        "        decoder=decoder,\n",
        "        fixed = fixed,)\n",
        "\n",
        "    # compile with optimizers and loss function of choice\n",
        "    progressive_ae_trainer.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.0, beta_2=0.99, epsilon=1e-8),\n",
        "        loss_fn=tf.keras.losses.MeanSquaredError(),\n",
        "        )\n",
        "\n",
        "    steps_per_epoch = iterations//resolution_batch_size_map[resolution]\n",
        "    # save_best_only is set to False as it is an adversarial loss\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(str(model_dir), save_weights_only=True, save_best_only=False, save_freq=10)\n",
        "\n",
        "    # Train at resolution\n",
        "    print('Resolution : {}'.format(resolution),flush=True)\n",
        "\n",
        "    print('Transition phase')\n",
        "    progressive_ae_trainer.fit(\n",
        "        dataset_train,\n",
        "        phase='transition',\n",
        "        resolution=resolution,\n",
        "        steps_per_epoch=steps_per_epoch, # necessary for repeat dataset\n",
        "        callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    print('Resolution phase')\n",
        "    progressive_ae_trainer.fit(\n",
        "        dataset_train,\n",
        "        phase='resolution',\n",
        "        resolution=resolution,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    #save the final weights\n",
        "    #print('Saving')\n",
        "    #encoder.save(str(model_dir.joinpath('encoder_res_{}'.format(resolution))))\n",
        "    #if not fixed: decoder.save(str(model_dir.joinpath('decoder_res_{}'.format(resolution))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW4UQJcc-yjf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b699131065e79a6393b7ec2bc47abaa4ef684186f6821415c92a21dbb855f1f9"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "train_autoencoder.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
